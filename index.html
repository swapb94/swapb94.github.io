<!DOCTYPE HTML>

<html>
	<head>
		<title>Swapnil Bhosale | PhD Researcher in Audio-visual Correspondence learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/swap.jpg" alt="Portrait of Swapnil Bhosale"/></span>
					<h1 id="logo"><a href="#">Swapnil Bhosale</a></h1><br>
					<h6>English approximation: <br> /Swup-Nil/ /Bho-slay/</h6>
					<p>PhD Student <br> Vision, Speech, Signal Processing</p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#one" class="active">About</a></li>
						<li><a href="#two">Selected Publications</a></li>
						<li><a href="#three">Research Experience</a></li>
					</ul>
				</nav>
				<footer>
					<ul class="icons">
						<li><a href="https://github.com/swapb94" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="mailto: s.bhosale@surrey.ac.uk" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="image main" data-position="center">
									<img src="images/banner_2.jpg" alt="" />
								</div>
								<div class="container">
									<!--header class="major">
										<h2>Swapnil Bhosale</h2>
										<p>Just an incredibly simple responsive site<br />
										template freebie by <a href="http://html5up.net">HTML5 UP</a>.</p>
									</header-->
									<p> I am a PhD student at the <a target="_blank" href="https://www.surrey.ac.uk/artificial-intelligence">University of Surrey's People-Centred AI Institute</a> specializing in multimodal deep learning, working at the intersection of vision, language, and audio processing. My focus is to leverage foundational AI models to learn audio-visual correspondence and solve real-world challenges. 
										I work within the <a target="_blank" href="https://surrey-uplab.github.io/"> Universal Perception (UP) Lab </a> under the guidance of <a target="_blank" href="https://www.surrey.ac.uk/people/eddy-zhu">Dr. Xiatian Zhu</a> and <a target="_blank" href="https://www.surrey.ac.uk/people/diptesh-kanojia">Dr. Diptesh Kanojia</a>.
										<br>

										Before starting my PhD, I worked as a researcher at <a target="_blank" href="https://www.tcs.com/what-we-do/research">TCS-Research, Mumbai</a> under <a target="_blank" href="https://sites.google.com/site/sunilkopparapu/Home">Dr. Sunil Kumar Kopparapu</a>, where I developed cutting-edge solutions in audio event detection, multimodal emotion recognition, and pathological speech processing, contributing to impactful publications and patents in speech and audio signal processing.
										
										</p>
									
									<p style="text-align:center;">
										<a href="https://scholar.google.com/citations?user=FsO6e24AAAAJ&hl=en&oi=ao" class="image"><img src="images/gscholar_logo.png" width="50" height="50"/><span class="label"></span></a> &nbsp; &nbsp;
										<a href="upload/Swapnil_CV_1224.pdf" class="image"><img src="images/CV_logo.png" width="50" height="50"/><span class="label"></span></a>
										<a href="upload/HypEE_Appendix.pdf" ><span class="label"></span></a>
									</p>
								</div>
							</section>

						<!-- Two -->
							<section id="two">
								<div class="container">
									<h3>Selected Publications</h3>
									<p>
									(A complete list of my publications is available <a target="_blank" href="https://scholar.google.com/citations?user=FsO6e24AAAAJ&hl=en&oi=ao">here</a>).
									</p>
									<p>
										<b><a target="_blank" href="https://arxiv.org/abs/2403.14203">Unsupervised Audio-Visual Segmentation with Modality Alignment</a></b>
										<br/>
										<i>AAAI (2025)</i>
										<br/>
									</p>
									<p>
										<b><a target="_blank" href="https://arxiv.org/pdf/2406.08920.pdf">AV-GS: Learning Material and Geometry Aware Priors for Novel View Acoustic Synthesis</a></b>
										<br/>
										<i>NeurIPS (2024)</i>
										<br/>
									</p>
									<p>
										<b><a target="_blank" href="https://arxiv.org/pdf/2410.15930">Centrality-aware Product Retrieval and Ranking</a></b>
										<br/>
										<i>EMNLP (2024) [Industry Track]</i>
										<br/>
									</p>
									<p>
										<b><a target="_blank" href="https://arxiv.org/pdf/2308.07293.pdf">DiffSED: Sound Event Detection with Denoising Diffusion</a></b>
										<br/>
										<i>AAAI (2024) [Oral]</i>
										<br/>
									</p>
									<p>
										<b><a target="_blank" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10096526">A Novel Metric For Evaluating Audio Caption Similarity</a></b>
										<br/>
										<i>IEEE ICASSP (2023)</i>
										<br/>
									</p>
																		<p>
										<b><a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S1746809421008867">Calibration Free Meta learning based approach for Subject Independent EEG Emotion Recognition</a></b>
										<br/>
										<i>Biomedical Signal Processing and Control 72 (2022)</i>
										<br/>
									</p>

									</p>
																		<p>
										<b><a target="_blank" href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/bhosale21_interspeech.pdf">Contrastive Learning of Cough Descriptors for Automatic COVID-19 Preliminary Diagnosis</a></b>
										<br/>
										<i>Interspeech (2021)</i>
										<br/>
									</p>

									</p>
									<p>
										<b><a target="_blank" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414845">Deep Lung Auscultation using Acoustic biomarkers for Abnormal Respiratory Sound Event Detection</a></b>
										<br/>
										<i>IEEE ICASSP (2021)</i>
										<br/>
									</p>

									<p>
										<b><a target="_blank" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054621">Deep Encoded Linguistic and Acoustic cues for Attention based End-to-End Speech Emotion Recognition</a></b>
										<br/>
										<i>IEEE ICASSP (2020)</i>
										<br/>
									</p>

									<p>
										<b><a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0885230821000206">Automatic Speaker Independent Dysarthric Speech Intelligibility Assessment System</a></b>
										<br/>
										<i>Computer Speech and Language (2021)</i>
										<br/>
									</p>

									<p>
										<b><a target="_blank" href="https://www.researchgate.net/profile/Sunil-Kumar-Kopparapu/publication/335828998_End-to-End_Spoken_Language_Understanding_Bootstrapping_in_Low_Resource_Scenarios/links/5e56106aa6fdccbeba031773/End-to-End-Spoken-Language-Understanding-Bootstrapping-in-Low-Resource-Scenarios.pdf">End-to-End Spoken Language Understanding: Bootstrapping in Low Resource Scenarios</a></b>
										<br/>
										<i>Interspeech (2019)</i>
										<br/>
									</p>
								</div>
							</section>

						<!-- Three -->
							<section id="three">
								<div class="container">
									<h3>Research Experience</h3>
																
									<div class="features">
										<article>
											<a href="#work" class="image"><img src="images/meta_rlr.jpg" width="10%" height="10%" alt=""/></a>
											<div class="inner">
												<p>
													Research Scientist Intern,
													<a target="_blank" href="https://tech.facebook.com/reality-labs/">Meta Reality Labs Research</a>,
													RLR Audio, Cambridge, UK
													<br/>
													<i>2025.03 ~ 2025.09</i>
													<br/>
													Real-time sound recognition for smart glasses; encoding acoustic awareness for AI interactions.
												</p>
											</div>
										</article>
										<article>
											<a href="#work" class="image"><img src="images/pai.jpg" width="10%" height="10%" alt=""/></a>
											<div class="inner">
												<p>
													PhD Researcher,
													<a target="_blank" href="https://x-up-lab.github.io/">Universal Perception (UP) lab</a>,
													People-Centred AI, University of Surrey, UK
													<br/>
													<i>2022.09 ~ Present</i>
													<br/>
													Vision and Language Processing.
												</p>
											</div>
										</article>
										<article>
											<a href="#work" class="image"><img src="images/tcs_research.jpg" alt=""/></a>
											<div class="inner">
												<p>
													Researcher <br>
													Speech and NLP team, <a target="_blank" href="https://www.tcs.com/research-and-innovation">TCS-Research</a>,<br>Mumbai, India.
													<br/>
													<i>2019.08 ~ 2022.09</i>
													<br/>
													Audio and Speech Signal Processing, Few-shot Audio Event Detection, Audio Captioning.
												</p><br>
												<p>
													Research Intern <br> 														Speech and NLP team, <a target="_blank" href="https://www.tcs.com/research-and-innovation">TCS-Research</a>,<br>Mumbai, India.<br/>
													<i>2019.01 ~ 2019.06</i>
													<br/>
													End-to-End Spoken Language Understanding.
												</p>
											</div>
										</article>
									</div>
								</div>
							</section>

					<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=0e1633&w=a&t=tt&d=EikwovVxvQmt7hb2UTBpy3kmwsKvb072ZIGwpkajf9g&co=0b4975&cmo=3acc3a&cmn=ff5353&ct=cdd4d9'></script>

					</div>

					<!-- Footer -->
					<section id="footer">
						<div class="container">
							
							<ul class="copyright">
								<li>&copy; Swapnil Bhosale. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
</body>
</html>




